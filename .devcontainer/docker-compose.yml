version: "3"
services:
  dev:
    image: wiiit/llama-cpu:python_3.10.12-pytorch_2.1.0
    container_name: dev-llama2-$USER
    # mem_limit: 8192m
    volumes:
      - ..:/workspace
    # ports:
    #   - "80:80"
    #   - "8000:8000"
    network_mode: "host"
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    command: ["/bin/bash"]